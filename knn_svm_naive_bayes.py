# -*- coding: utf-8 -*-
"""knn_svm_naive_bayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12hiRQ6a63nAaCrFIH8IOYobZXm_5Qmyy
"""

import pandas as pd #biblioteca utilizada para o tratamento de dados via dataframes 
import numpy as np #biblioteca utilizada para o tratamento de valores numéricos (vetores e matrizes)
import matplotlib.pyplot as plt #biblioteca utilizada para construir os gráficos
import seaborn as sns #biblioteca utilizada para construir os gráficos
from sklearn.linear_model import LogisticRegression # biblioteca para regressão logística 
from sklearn.decomposition import PCA #biblioteca para PCA
from sklearn.feature_selection import RFE #biblioteca para aplicação RFE
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LinearRegression #importa o modelo de regressão linear univariada
from sklearn.metrics import r2_score #método para o cálculo do R2 (coeficiente de determinação)
from sklearn import preprocessing

from google.colab import files  #biblioteca utilizada para carregar os dados para o google colab
uploaded = files.upload()

data_frame = pd.read_csv('insurance.csv')

data_frame['region'].unique()

data_frame.head()

data_frame.info()

data_frame.describe()

data_frame.isnull().sum()

mean_age = data_frame['age'].mean()

data_frame['age'].fillna(mean_age,inplace=True)

data_frame.isnull().sum()

data_frame.groupby(['region']).mean()

label_encoder_region = LabelEncoder()
data_frame['region_encoded'] = label_encoder_region.fit_transform(data_frame['region'])

data_frame.head()

one_hot_smoker = pd.get_dummies(data_frame['smoker'])
data_frame =  data_frame.join(one_hot_smoker)

one_hot_sex = pd.get_dummies(data_frame['sex'])
data_frame =  data_frame.join(one_hot_sex)

data_frame.head()

data_frame.corr()

x = data_frame[['age','bmi','children','female','male','yes','no']]

y = data_frame['charges']

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))

x_scaled = scaler.fit_transform(x)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.3, random_state=42)

from sklearn.neighbors import KNeighborsRegressor

from sklearn.metrics import mean_squared_error

from sklearn.preprocessing import MinMaxScaler

model_KNN = KNeighborsRegressor()

model_KNN.fit(X_train,y_train)

pred = model_KNN.predict(X_test)

model_KNN.score(X_test,y_test)

n_k = 100

list_R2 = [] 
list_knn = []

for x in range(1,n_k):
  model_KNN = KNeighborsRegressor(n_neighbors=x)
  model_KNN.fit(X_train,y_train)
  R2 = model_KNN.score(X_test,y_test)
  print(' N_K: {} R2: {}'.format(x,R2))
  list_R2.append(R2)
  list_knn.append(x)

len(list_R2)

sns.lineplot(x=range(1,n_k), y=list_R2)

from sklearn.tree import DecisionTreeRegressor

tree_regressor = DecisionTreeRegressor(random_state=0)

tree_regressor.fit(X_train,y_train)

pred_tree = tree_regressor.predict(X_test)

r2_score(y_test,pred_tree)

from sklearn import tree

import pydotplus

from IPython.display import Image

tree.plot_tree(tree_regressor)

# Create DOT data
dot_data = tree.export_graphviz(tree_regressor, out_file=None)

# Draw graph
graph = pydotplus.graph_from_dot_data(dot_data)  

# Show graph
Image(graph.create_png())

from sklearn.svm import SVR

modelSvr = SVR(kernel='rbf',C=10000)

modelSvr.fit(X_train, y_train)

predSvr = modelSvr.predict(X_test)

r2_score(y_test, predSvr)









from google.colab import files  #biblioteca utilizada para carregar os dados para o google colab
uploaded = files.upload()

data_frame_h = pd.read_csv('heart.csv')

data_frame_h.head()

data_frame_h.info()

data_frame_h.describe()

data_frame_h.isnull().sum()

data_frame_h.corr()

x = data_frame_h[['age','sex','thalach','exang','oldpeak']]

y = data_frame_h['target']

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

from sklearn.naive_bayes import GaussianNB

model_NaiveBayes = GaussianNB()

model_NaiveBayes.fit(X_train,y_train)

pred = model_NaiveBayes.predict(X_test)

# Importando métricas para validação do modelo
from sklearn.metrics import  accuracy_score

accuracy_score(y_test,pred)

from sklearn.ensemble import RandomForestClassifier

clf_random = RandomForestClassifier(n_estimators=80, random_state=0)

clf_random.fit(X_train,y_train)

pred_random = clf_random.predict(X_test)

accuracy_score(y_test,pred_random)

clf_random.n_estimators

clf_random

dot_data = tree.export_graphviz(clf_random.estimators_[0], out_file=None)

# Draw graph
graph = pydotplus.graph_from_dot_data(dot_data)  

# Show graph
Image(graph.create_png())

from sklearn.svm import SVC

modelSvc = SVC(C=1000, kernel='rbf')

modelSvc.fit(X_train, y_train)

predSvc = modelSvc.predict(X_test)

accuracy_score(y_test, predSvc)



from sklearn.datasets.samples_generator import make_blobs

X, y = make_blobs(n_samples=500, centers=4, cluster_std=0.90)

plt.scatter(X[:,0], X[:,1])

from sklearn.cluster import KMeans

wss = []

for i in range(1, 20):
  k = KMeans(n_clusters=i)
  k.fit(X)
  print('n cluster: {} wss {}'.format(i, k.inertia_))
  wss.append(k.inertia_)

plt.plot(range(1,20), wss)

k = KMeans(n_clusters=3)

k.fit_predict(X)

plt.scatter(X[:,0], X[:,1])
plt.scatter(k.cluster_centers_[:,0], k.cluster_centers_[:,1])

