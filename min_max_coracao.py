# -*- coding: utf-8 -*-
"""min_max_coracao.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-zJsUJaqOu5XfUp_ZFlyuPi_HkXm4OdJ
"""

import pandas as pd
# dataset = pd.read_csv("https://raw.githubusercontent.com/ect-info/ml/master/dados/Social_Network_Ads.csv")
dataset = pd.read_csv("heart.csv")

dataset.head()

dataset.info()

dataset.describe()

# x_entrada = dataset[['Age', 'EstimatedSalary']]
# y_saida = dataset['Purchased']

x_entrada = dataset[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]
y_saida = dataset['target']

x_entrada

y_saida

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x_entrada, y_saida, test_size = 0.25, random_state = 0)

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

tamanho_entrada = x_entrada.shape[1]

import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping

model = Sequential()
model.add(Dense(40, input_shape=[x_entrada.shape[1]], activation='relu'))

model.add(Dense(40, activation='relu'))
model.add(Dense(40, activation='relu'))

model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())

history = model.fit(x_train, y_train,
                    epochs=200,
                    batch_size=35,
                    verbose=1,
                    validation_split=0.2,
                    callbacks=[EarlyStopping(monitor='val_loss', patience=5)])

import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['loss', 'val_loss'])
plt.title('Loss')
plt.xlabel('Epoch')

y_pred = model.predict(x_test)

y_pred_bin = [ ( 1 if elem > 0.5 else 0) for elem in y_pred ]

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred_bin))

import seaborn as sns
from sklearn.metrics import confusion_matrix
import numpy as np

cf_matrix = confusion_matrix(y_test, y_pred_bin)
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues')