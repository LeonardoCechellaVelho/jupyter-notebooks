# -*- coding: utf-8 -*-
"""kmeans_iris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1seX32FQXV8jaA1WiSaB4Bt5XGTAGNPVR

# Desafio de Support Vector Machines 

Bem vindo a seu projet de Support Vector Machine Project! Basta seguir o notebook e as instruções abaixo. Vamos analisar o famoso conjunto de dados da íris!

## Os dados
Para esta série de palestras, estaremos usando o famoso [conjunto de dados de íris](http://en.wikipedia.org/wiki/Iris_flower_data_set).

O conjunto de dados florais Iris ou o conjunto de dados Iris de Fisher é um conjunto de dados multivariados introduzido por Sir Ronald Fisher em 1936 como um exemplo de análise discriminante.

O conjunto de dados é composto por 50 amostras de cada uma das três espécies de íris (Iris setosa, Iris virginica e Iris versicolor), de modo que 150 amostras totais. Foram medidas quatro características de cada amostra: o comprimento e a largura das sépalas e pétalas, em centimetros.

Aqui está uma imagem dos três diferentes tipos de íris:

Bem-vindo ao seu Projeto de Máquina de Vetores de Suporte! Basta seguir o caderno e as instruções abaixo. Vamos analisar o famoso conjunto de dados da íris!
"""

# Uma iris setosa
from IPython.display import Image
url = 'http://upload.wikimedia.org/wikipedia/commons/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg'
Image(url,width=300, height=300)

# Uma iris versicolor
from IPython.display import Image
url = 'http://upload.wikimedia.org/wikipedia/commons/4/41/Iris_versicolor_3.jpg'
Image(url,width=300, height=300)

# Uma iris virginica
from IPython.display import Image
url = 'http://upload.wikimedia.org/wikipedia/commons/9/9f/Iris_virginica.jpg'
Image(url,width=300, height=300)

"""O conjunto de dados da íris contém medidas de 150 flores da íris de três espécies diferentes.

As três classes no conjunto de dados Iris:

     Iris-setosa (n = 50)
     Iris-versicolor (n = 50)
     Iris-virginica (n = 50)

Os quatro recursos do conjunto de dados Iris:

     comprimento sepal em cm
     Largura sepal em cm
     comprimento da pétala em cm
     largura da pétala em cm

## Obter os dados

** Use seaborn para obter os dados da íris usando: iris = sns.load_dataset('iris') **
"""

import seaborn as sns
data_frame = sns.load_dataset('iris')

"""## Realizar pré-processamento



*   Faça uma análise dos dados com HEAD, info, describe
*   Verifique os possíveis dados faltantes 




"""

data_frame.head()

data_frame.info()

data_frame.describe()

"""
## Análise de correlação

Utilize de algum  método de correlação para verificar as correlações das variáveis

"""

data_frame.isnull().sum()

"""# Divisao treino-teste

** Divida seus dados em um conjunto de treinamento e um conjunto de testes. **
"""

from sklearn.model_selection import train_test_split

x = data_frame[['sepal_length','sepal_width','petal_length','petal_width']]

y = data_frame[['species']]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

"""# Treino um modelo

Agora é hora de treinar um classificador de SVM.

** Chame o modelo SVC() da sklearn e ajuste o modelo aos dados de treinamento. **
"""

from sklearn.svm import SVC

model_SVC = SVC(C=10000, kernel='rbf')

model_SVC.fit(x_train,y_train)

"""## Avaliação do modelo

** Agora obtenha previsões do modelo e crie uma matriz de confusão e um relatório de classificação. **
"""

predictions = model_SVC.predict(x_test)

from sklearn.metrics import classification_report,confusion_matrix

classification = classification_report(y_test,predictions)

confusion_matrix = confusion_matrix(y_test,predictions)

print('\n*Classification Report:\n', classification)

"""# Desafio de K Means Clustering  


Para este desafio, tentaremos usar o KMeans Clustering para agrupar Universidades em dois grupos: Privadas e Públicas.


___
É muito importante observar, nós realmente temos os rótulos para este conjunto de dados, mas NÃO os usaremos para o algoritmo de agrupamento KMeans, pois esse é um algoritmo de aprendizado não supervisionado. **

Ao usar o algoritmo Kmeans em situações reais, você não possuirá rótulos. Nesse caso, usaremos os rótulos para tentar ter uma idéia do quão bem o algoritmo foi executado, apenas.
___

"""

from sklearn.datasets.samples_generator import make_blobs
from sklearn.cluster import KMeans
import random
from matplotlib import pyplot as plt

"""Utilize esse código para gerar 'clusters' de pontos para utilizar no K-means

Os clusters são realizados de forma randomica. 
"""

X, y = make_blobs(n_samples=300, centers=random.randint(1,20), cluster_std=0.60)

"""Plot os cluster utilizando os SCATTER plot, da lib matplotlib"""

from sklearn.datasets.samples_generator import make_blobs

plt.scatter(X[:,0],X[:,1])

"""Faça uma varredura de n_cluster, realize treinamento e crie uma lista de valores kmeans.inertia_ para verificar o melhor valor de n_cluster"""

from sklearn.cluster import KMeans

wss=[]

for i in range(1,20):
  kmeans = KMeans(n_clusters=i)
  kmeans.fit(X)
  print('n_cluster : {} WSS: {}'.format(i,kmeans.inertia_))
  wss.append(kmeans.inertia_)

"""Crie um plot -> N cluster x lista_wcss"""

plt.plot(range(1,20),wss)

"""Crie um modelo de K-means com u número de cluster ideal e realize a predição de X"""

kmeans = KMeans(n_clusters=7)

pred_kmeans = kmeans.fit_predict(X)

"""Plot os clusters utilizando os SCATTER plot e os centróides, da lib matplotlib"""

plt.scatter(X[:,0],X[:,1])
plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=500)